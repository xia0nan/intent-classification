{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Import\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting point\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PATH_HOME = Path.home()\n",
    "PATH_PROJ = Path.cwd()\n",
    "PATH_DATA = PATH_PROJ\n",
    "\n",
    "sys.path.append(str(PATH_PROJ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Statement request</td>\n",
       "      <td>i would like a copy of my statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Statement request</td>\n",
       "      <td>please send me a copy of my statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label             Intent                              Questions\n",
       "0      0  Statement request    i would like a copy of my statement\n",
       "1      0  Statement request  please send me a copy of my statement"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "df_train = pd.read_csv('data2.csv')\n",
    "df_train.dropna(inplace=True)\n",
    "print(df_train.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>i would like a copy of my statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>please send me a copy of my statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              intent                                  query\n",
       "0  Statement request    i would like a copy of my statement\n",
       "1  Statement request  please send me a copy of my statement"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename dataframe\n",
    "df_train = df_train.rename(columns={'Intent': 'intent', 'Questions': 'query'})\n",
    "df_train = df_train[['intent', 'query']]\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>User Clicked intent</th>\n",
       "      <th>Google-intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do i submit a dispute?</td>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>Dispute status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I lost my card</td>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>Lost or compromised cards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Question             User Clicked intent  \\\n",
       "0  how do i submit a dispute?   Cancel credit card transaction   \n",
       "1               I lost my card       Lost or compromised cards   \n",
       "\n",
       "               Google-intent  \n",
       "0             Dispute status  \n",
       "1  Lost or compromised cards  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "df_test = pd.read_csv('uat_data_intent.csv')\n",
    "df_test.dropna(inplace=True)\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>User Clicked intent</th>\n",
       "      <th>Google-intent</th>\n",
       "      <th>correct_google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do i submit a dispute?</td>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>Dispute status</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I lost my card</td>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have not received my purchases from the merc...</td>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>Cancel ATM Card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have a transaction that i did not do</td>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how to terminate my card?</td>\n",
       "      <td>Cancel Credit or Debit Card</td>\n",
       "      <td>Card Cancellation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                        how do i submit a dispute?    \n",
       "1                                     I lost my card   \n",
       "2  I have not received my purchases from the merc...   \n",
       "3             i have a transaction that i did not do   \n",
       "4                          how to terminate my card?   \n",
       "\n",
       "              User Clicked intent                   Google-intent  \\\n",
       "0  Cancel credit card transaction                  Dispute status   \n",
       "1       Lost or compromised cards       Lost or compromised cards   \n",
       "2  Cancel credit card transaction                 Cancel ATM Card   \n",
       "3  Cancel credit card transaction  Cancel credit card transaction   \n",
       "4     Cancel Credit or Debit Card               Card Cancellation   \n",
       "\n",
       "   correct_google  \n",
       "0               0  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['correct_google'] = np.where(df_test['User Clicked intent'] == df_test['Google-intent'], 1, 0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google NLU accuracy is 78.1%\n"
     ]
    }
   ],
   "source": [
    "google_accuracy = sum(df_test['correct_google']) / len(df_test['correct_google'])\n",
    "print(\" Google NLU accuracy is {:.1%}\".format(google_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>how do i submit a dispute?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>I lost my card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intent                        query\n",
       "0  Cancel credit card transaction  how do i submit a dispute? \n",
       "1       Lost or compromised cards               I lost my card"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename dataframe\n",
    "df_test = df_test.rename(columns={'User Clicked intent': 'intent', 'Question': 'query'})\n",
    "df_test = df_test[['intent', 'query']]\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Basic text cleaning\n",
    "        \n",
    "        1. lowercase\n",
    "        2. remove special characters\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenize(text):\n",
    "    \"\"\" tokenize text using NLTK and join back as sentence\"\"\"\n",
    "    # import nltk\n",
    "    # nltk.download('punkt')\n",
    "    return ' '.join(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for spacy tokenizer\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = nlp(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_TfidfVectorizer(sentences):\n",
    "    \"\"\" Get idf dictionary by using TfidfVectorizer\n",
    "    \n",
    "    Args:\n",
    "        sentences (list): list of input sentences (str)\n",
    "\n",
    "    Returns:\n",
    "        idf (dict): idf[word] = inverse document frequency of that word in all training queries\n",
    "    \"\"\"\n",
    "    # use customized Spacy tokenizer\n",
    "    vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)\n",
    "    vectorizer.fit(sentences)\n",
    "    # TODO: normalize the idf weights\n",
    "    idf = {k:vectorizer.idf_[v] for k,v in vectorizer.vocabulary_.items()}\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vec(sentence, word2vec, idf=None):\n",
    "    \"\"\" Get embedding of sentence by using word2vec embedding of words\n",
    "    \n",
    "    If idf is provided, the sentence is the weighted embedding by\n",
    "        SUM( embedding[word] x idf[word] )\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): input sentence\n",
    "        word2vec (dict): loaded word2vec model from Gensim\n",
    "        idf (dict, optional): inverse document frequency of words in all queries\n",
    "\n",
    "    Returns:\n",
    "        emb (np.array): 300-dimentions embedding of sentence\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    words = [word for word in words if word in word2vec.vocab]\n",
    "    \n",
    "    # if no word in word2vec vocab, return 0x300 embedding\n",
    "    if len(words)==0:\n",
    "        return np.zeros((300,), dtype='float32')\n",
    "    \n",
    "    # use mean if no idf provided\n",
    "    if idf is None:\n",
    "        emb = word2vec[words].mean(axis=0)\n",
    "    else:\n",
    "        # get all idf of words, if new word is not in idf, assign 0.0 weights\n",
    "        idf_series = np.array([idf.get(word, 0.0) for word in words])\n",
    "        # change shape to 1 x num_of_words\n",
    "        idf_series = idf_series.reshape(1, -1)\n",
    "        # use matrix multiplication to get weighted word vector sum for sentence embeddings\n",
    "        emb = np.matmul(idf_series, word2vec[words]).reshape(-1)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_centre(sentences, word2vec, idf=None, num_features=300):\n",
    "    \"\"\" Get sentences centre by averaging all embeddings of sentences in a list\n",
    "    \n",
    "    Depends on function get_sentence_vec()\n",
    "    \n",
    "    Args:\n",
    "        sentence (list): list of input sentences (str)\n",
    "        word2vec (dict): loaded word2vec model from Gensim\n",
    "        idf (dict, optional): inverse document frequency of words in all queries\n",
    "\n",
    "    Returns:\n",
    "        emb (np.array): 300-dimentions embedding of sentence\n",
    "    \"\"\"\n",
    "    # convert list of sentences to their vectors\n",
    "    sentences_vec = [get_sentence_vec(sentence, word2vec, idf) for sentence in sentences]\n",
    "    \n",
    "    # each row in matrix is 300 dimensions embedding of a sentence\n",
    "    sentences_matrix = np.vstack(sentences_vec)\n",
    "    # print(sentences_matrix.shape)\n",
    "    \n",
    "    # average of all rows, take mean at y-axis\n",
    "    sentences_centre = sentences_matrix.mean(axis=0)\n",
    "    \n",
    "    # result should be (300,) same as single sentence\n",
    "    # print(sentences_centre.shape)\n",
    "    return sentences_centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_centre(df, intent_list, word2vec, idf=None):\n",
    "    \"\"\" get intent cluster centre based on intent list and word embeddings\n",
    "    \n",
    "    Depends on function get_sentences_centre()\n",
    "    \n",
    "    Args:\n",
    "        intent_list (list): List of unique intents(str)\n",
    "        word2vec (dict): word embeddings dictionary \n",
    "\n",
    "    Returns:\n",
    "        result (dict): intent cluster centres in dictionary format - {intent1:embedding1, intent2:embedding2,...}\n",
    "    \"\"\" \n",
    "    result = {intent:get_sentences_centre(df[df.intent == intent]['query'].values, word2vec, idf) for intent in intent_list}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(df_in, word2vec, leave_one_out=False, idf=False):\n",
    "    \"\"\" Get distance for each query to every intent center\n",
    "    \n",
    "    Depends on function get_cluster_centre()\n",
    "    \n",
    "    Args:\n",
    "        df_in (pd.DataFrame): input dataframe with intent and query\n",
    "        word2vec (dict): word embeddings dictionary \n",
    "        leave_one_out (bool): whether leave the input query out of training\n",
    "        idf (bool): whether use weighted word vectors to get sentence embedding\n",
    "\n",
    "    Returns:\n",
    "        result (pd.DataFrame): distance matrix for each query, lowest distance intent idealy should match label\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    intent_list = df.intent.unique().tolist()\n",
    "    \n",
    "    if leave_one_out:\n",
    "        # print(\"Leave one out\")\n",
    "        sentence_distance = []\n",
    "        \n",
    "        for ind in df.index:\n",
    "            sentence_distance_tmp = []\n",
    "            query = df.loc[ind, 'query']\n",
    "            df_data = df.drop(ind)\n",
    "            \n",
    "            sentence_centre_dic = get_cluster_centre(df_data, intent_list, word2vec, idf)\n",
    "            for intent in intent_list:\n",
    "                sentence_distance_tmp.append(cosine_distances(get_sentence_vec(query, word2vec, idf).reshape(1,-1), \n",
    "                                                              sentence_centre_dic[intent].reshape(1,-1)).item())\n",
    "            sentence_distance.append(sentence_distance_tmp)\n",
    "\n",
    "        df_sentence_distance = pd.DataFrame(sentence_distance, columns=intent_list)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        result = pd.concat([df, df_sentence_distance], axis=1)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        sentence_centre_dic = get_cluster_centre(df, intent_list, word2vec, idf)\n",
    "        # build dataframe that contains distance between each query to all intent cluster centre\n",
    "        for intent in intent_list:\n",
    "            # distance = cosine_similarity(sentence embedding, intent cluster centre embedding)\n",
    "            df[intent] = df['query'].apply(lambda x: cosine_distances(get_sentence_vec(x, word2vec, idf).reshape(1,-1), \n",
    "                                                                      sentence_centre_dic[intent].reshape(1,-1)).item())\n",
    "        result = df\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_distance_matrix(df_in):\n",
    "    \"\"\" Evaluate distance matrix by compare closest intent center and label \"\"\"\n",
    "    df = df_in.copy()\n",
    "    df.set_index(['intent', 'query'], inplace=True)\n",
    "    df['cluster'] = df.idxmin(axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['correct'] = (df.cluster == df.intent)\n",
    "    accuracy = sum(df.correct) / len(df)\n",
    "    # print(\"Accuracy for distance-based classification is\", '{:.2%}'.format(result))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_clustering_accuracy(df_in, word2vec):\n",
    "    \"\"\" test accuracy based on distance of sentence to each cluster center\"\"\"\n",
    "    df_result = get_distance_matrix(df_in, word2vec)\n",
    "    # print(df_result.head())\n",
    "    accuracy = evaluate_distance_matrix(df_result)\n",
    "    return df_result, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "def test_idf_acc(df_in, word2vec, idf):\n",
    "    df_result = get_distance_matrix(df_in, word2vec, leave_one_out=False, idf=idf)\n",
    "    # print(df_result.head())\n",
    "    accuracy = evaluate_distance_matrix(df_result)\n",
    "    return df_result, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing questions\n",
    "df_train['query'] = df_train['query'].apply(clean_text)\n",
    "df_train['query'] = df_train['query'].apply(nltk_tokenize)\n",
    "df_train['query'] = df_train['query'].apply(lambda x:' '.join([token.lemma_ for token in nlp(x) if token.lemma_ not in stop_words]))\n",
    "df_train['query'] = df_train['query'].str.lower()\n",
    "\n",
    "\n",
    "# preprocessing test as well\n",
    "df_test['query'] = df_test['query'].apply(clean_text)\n",
    "df_test['query'] = df_test['query'].apply(nltk_tokenize)\n",
    "df_test['query'] = df_test['query'].apply(lambda x:' '.join([token.lemma_ for token in nlp(x) if token.lemma_ not in stop_words]))\n",
    "df_test['query'] = df_test['query'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>like copy -pron- statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>send -pron- copy -pron- statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              intent                              query\n",
       "0  Statement request         like copy -pron- statement\n",
       "1  Statement request  send -pron- copy -pron- statement"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>submit dispute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>lose -pron- card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intent             query\n",
       "0  Cancel credit card transaction    submit dispute\n",
       "1       Lost or compromised cards  lose -pron- card"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Statement request', 'Passbook savings accounts']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_list = df_train.intent.unique().tolist()\n",
    "intent_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_intent_list = df_test.intent.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(intent_list) == set(test_intent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in test_intent_list:\n",
    "    if item not in intent_list:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passbook savings accounts\n",
      "Credit card statement\n",
      "Debit card statement\n",
      "Investment account statement\n",
      "Change of billing cycle\n",
      "Student Loan\n",
      "Tuition fee loan\n",
      "Education loan\n",
      "Study loan\n",
      "Cancel Fund Transfer\n",
      "CRS Enquiries\n",
      "Give a compliment\n",
      "File a complaint\n",
      "Unsuccessful card transaction\n",
      "Card Renewal\n",
      "Card Promotions\n",
      "Open OCBC Singapore Account\n",
      "Open OCBC Securities Account \n",
      "Open OCBC Malaysia Account\n",
      "Open NISP Account\n",
      "Request for sponsorship\n",
      "Card Application\n",
      "Apply for ATM card\n",
      "Change credit card limit\n",
      "Decrease credit card limit\n",
      "Credit card application rejection\n"
     ]
    }
   ],
   "source": [
    "for item in intent_list:\n",
    "    if item not in test_intent_list:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get idf\n",
    "idf = get_idf_TfidfVectorizer(df_train['query'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing accuracy for word2vec + IDF is 91.89%\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "try:\n",
    "    word2vec\n",
    "except NameError:\n",
    "    word2vec = api.load(\"word2vec-google-news-300\")  \n",
    "\n",
    "df_result, accuracy = test_idf_acc(df_train, word2vec, idf)\n",
    "print(\"Traing accuracy for word2vec + IDF is\", '{:.2%}'.format(accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare: Accuracy without IDF is ~90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster centers from training set\n",
    "idf = get_idf_TfidfVectorizer(df_train['query'].tolist())\n",
    "dict_cluster = get_cluster_centre(df_train, intent_list, word2vec, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix_idf(df_test, intent_list, dict_cluster, word2vec, idf):\n",
    "    \"\"\" Get distance for each query to every intent center\n",
    "        \n",
    "    Args:\n",
    "        df_test (pd.DataFrame): input test dataframe with intent and query\n",
    "        intent_list (list): list of intents to loop through\n",
    "        dict_cluster (dict): dictionary of cluster centres\n",
    "        word2vec (dict): word embeddings dictionary\n",
    "        idf (dict): idf of each words\n",
    "\n",
    "    Returns:\n",
    "        result (pd.DataFrame): distance matrix for each query, lowest distance intent idealy should match label\n",
    "    \"\"\"\n",
    "    df = df_test.copy()\n",
    "    for intent in intent_list:\n",
    "        # distance = cosine_similarity(sentence embedding, intent cluster centre embedding)\n",
    "        df[intent] = df['query'].apply(lambda x: cosine_distances(get_sentence_vec(x, word2vec, idf).reshape(1,-1), \n",
    "                                                                  dict_cluster[intent].reshape(1,-1)).item())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "      <th>Statement request</th>\n",
       "      <th>Passbook savings accounts</th>\n",
       "      <th>Card statements</th>\n",
       "      <th>Credit card statement</th>\n",
       "      <th>Debit card statement</th>\n",
       "      <th>Investment account statement</th>\n",
       "      <th>Home loan account statement</th>\n",
       "      <th>360 Account interest dispute</th>\n",
       "      <th>...</th>\n",
       "      <th>Paying a cancelled credit card</th>\n",
       "      <th>How to close my account</th>\n",
       "      <th>Card dispute</th>\n",
       "      <th>Change credit card limit</th>\n",
       "      <th>Increase credit card limit</th>\n",
       "      <th>Decrease credit card limit</th>\n",
       "      <th>Credit card application rejection</th>\n",
       "      <th>Rebates</th>\n",
       "      <th>How to redeem rewards</th>\n",
       "      <th>Update details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>submit dispute</td>\n",
       "      <td>0.859452</td>\n",
       "      <td>0.956631</td>\n",
       "      <td>0.855401</td>\n",
       "      <td>0.845590</td>\n",
       "      <td>0.878371</td>\n",
       "      <td>0.865033</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.792492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784627</td>\n",
       "      <td>0.882740</td>\n",
       "      <td>0.688009</td>\n",
       "      <td>0.862475</td>\n",
       "      <td>0.860961</td>\n",
       "      <td>0.921762</td>\n",
       "      <td>0.781087</td>\n",
       "      <td>0.864479</td>\n",
       "      <td>0.946258</td>\n",
       "      <td>0.915108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>lose -pron- card</td>\n",
       "      <td>0.793683</td>\n",
       "      <td>0.757093</td>\n",
       "      <td>0.703357</td>\n",
       "      <td>0.654635</td>\n",
       "      <td>0.690902</td>\n",
       "      <td>0.745970</td>\n",
       "      <td>0.770254</td>\n",
       "      <td>0.704963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541351</td>\n",
       "      <td>0.600998</td>\n",
       "      <td>0.579094</td>\n",
       "      <td>0.529235</td>\n",
       "      <td>0.524934</td>\n",
       "      <td>0.598681</td>\n",
       "      <td>0.630182</td>\n",
       "      <td>0.737598</td>\n",
       "      <td>0.683356</td>\n",
       "      <td>0.847152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intent             query  Statement request  \\\n",
       "0  Cancel credit card transaction    submit dispute           0.859452   \n",
       "1       Lost or compromised cards  lose -pron- card           0.793683   \n",
       "\n",
       "   Passbook savings accounts  Card statements  Credit card statement  \\\n",
       "0                   0.956631         0.855401               0.845590   \n",
       "1                   0.757093         0.703357               0.654635   \n",
       "\n",
       "   Debit card statement  Investment account statement  \\\n",
       "0              0.878371                      0.865033   \n",
       "1              0.690902                      0.745970   \n",
       "\n",
       "   Home loan account statement  360 Account interest dispute  ...  \\\n",
       "0                     0.869588                      0.792492  ...   \n",
       "1                     0.770254                      0.704963  ...   \n",
       "\n",
       "   Paying a cancelled credit card  How to close my account  Card dispute  \\\n",
       "0                        0.784627                 0.882740      0.688009   \n",
       "1                        0.541351                 0.600998      0.579094   \n",
       "\n",
       "   Change credit card limit  Increase credit card limit  \\\n",
       "0                  0.862475                    0.860961   \n",
       "1                  0.529235                    0.524934   \n",
       "\n",
       "   Decrease credit card limit  Credit card application rejection   Rebates  \\\n",
       "0                    0.921762                           0.781087  0.864479   \n",
       "1                    0.598681                           0.630182  0.737598   \n",
       "\n",
       "   How to redeem rewards  Update details  \n",
       "0               0.946258        0.915108  \n",
       "1               0.683356        0.847152  \n",
       "\n",
       "[2 rows x 79 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_cluster = get_distance_matrix_idf(df_test, intent_list, dict_cluster, word2vec, idf)\n",
    "df_test_cluster.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_cols = list(df_test_cluster.columns.values)[2:]\n",
    "# verify\n",
    "set(intent_list) == set(cluster_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_3_clusters(data, intent_list):\n",
    "    data = data.copy()\n",
    "    cluster_cols = intent_list.copy()\n",
    "\n",
    "    data['clusters_top3'] = data.apply(lambda x: np.argsort(x[cluster_cols].values)[:3].tolist(), axis=1)\n",
    "\n",
    "    intents = cluster_cols # get all tickers\n",
    "    intent2index = {v: i for (i, v) in enumerate(intents)}\n",
    "\n",
    "    data['target'] = data['intent'].apply(lambda x: intent2index[x])\n",
    "\n",
    "    top_clusters_cols = pd.DataFrame(data['clusters_top3'].values.tolist(),columns = ['clusters_1','clusters_2','clusters_3']).reset_index(drop=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = pd.concat([data,top_clusters_cols], axis=1)\n",
    "\n",
    "    data.drop(columns = 'clusters_top3', inplace=True)\n",
    "    data.drop(columns = cluster_cols, inplace=True)\n",
    "    \n",
    "    # print(data.head())\n",
    "    return data, intent2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>submit dispute</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>lose -pron- card</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>receive -pron- purchase merchant cancel -pron-</td>\n",
       "      <td>17</td>\n",
       "      <td>67</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>transaction</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cancel Credit or Debit Card</td>\n",
       "      <td>terminate -pron- card</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intent  \\\n",
       "0  Cancel credit card transaction   \n",
       "1       Lost or compromised cards   \n",
       "2  Cancel credit card transaction   \n",
       "3  Cancel credit card transaction   \n",
       "4     Cancel Credit or Debit Card   \n",
       "\n",
       "                                            query  target  clusters_1  \\\n",
       "0                                  submit dispute      17          25   \n",
       "1                                lose -pron- card      43          43   \n",
       "2  receive -pron- purchase merchant cancel -pron-      17          67   \n",
       "3                                     transaction      17          17   \n",
       "4                           terminate -pron- card      53          52   \n",
       "\n",
       "   clusters_2  clusters_3  \n",
       "0          69          21  \n",
       "1          53          44  \n",
       "2          52          53  \n",
       "3          21          39  \n",
       "4          53          40  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_cluster_top_n, _ = get_top_3_clusters(df_test_cluster, cluster_cols)\n",
    "df_test_cluster_top_n.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data, top=1):\n",
    "    data = data.copy()\n",
    "    \n",
    "    assert top in (1,2,3), \"top must be in (0, 1, 2)\"\n",
    "    \n",
    "    if top == 1:\n",
    "        # top 1 accuracy\n",
    "        accuracy = (data[(data['clusters_1'] == data['target'])].shape[0] / data.shape[0])\n",
    "    elif top == 2:\n",
    "        # top 2 accuracy\n",
    "        data[\"exists\"] = data.drop(data.columns[[0,1,2,5]], 1).isin(data[\"target\"]).any(1)\n",
    "        accuracy = sum(data['exists'])/ data.shape[0]\n",
    "    elif top == 3:\n",
    "        # top 3 accuracy\n",
    "        data[\"exists\"] = data.drop(data.columns[[0,1,2]], 1).isin(data[\"target\"]).any(1)\n",
    "        accuracy = sum(data['exists'])/ data.shape[0]\n",
    "    else:\n",
    "        raise ValueError(\"top must be in (0, 1, 2)\") \n",
    "    \n",
    "    print('Accuracy for top {} clustering result is {:.1%}'.format(top, accuracy))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for top 1 clustering result is 71.9%\n",
      "Accuracy for top 2 clustering result is 82.8%\n",
      "Accuracy for top 3 clustering result is 87.5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(df_test_cluster_top_n, 1)\n",
    "get_accuracy(df_test_cluster_top_n, 2)\n",
    "get_accuracy(df_test_cluster_top_n, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with NLP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>like copy -pron- statement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>send -pron- copy -pron- statement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              intent                              query  target  clusters_1  \\\n",
       "0  Statement request         like copy -pron- statement       0           0   \n",
       "1  Statement request  send -pron- copy -pron- statement       0           0   \n",
       "\n",
       "   clusters_2  clusters_3  \n",
       "0           2           3  \n",
       "1           2           3  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, intent2index = get_top_3_clusters(df_result, cluster_cols)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(intent_list):\n",
    "    \"\"\" Get list of keywords from intent \"\"\"\n",
    "    keywords = []\n",
    "    for intent in list(set(intent_list)):\n",
    "        keywords.extend(intent.strip().split(' '))\n",
    "    keyword_list = list(set(keywords))\n",
    "    keyword_list = [i.lower() for i in keyword_list if i.lower() not in stop_words]\n",
    "    keyword_list.append('nsip')\n",
    "\n",
    "    keyword_list_lemma = []\n",
    "    text = nlp(' '.join([w for w in keyword_list]))\n",
    "    for token in text:\n",
    "        keyword_list_lemma.append(token.lemma_)\n",
    "    return keyword_list_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list_lemma = get_keywords(intent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_features(df):\n",
    "    \"\"\" Get keyword features from dataframe \"\"\"\n",
    "    data = df.copy()\n",
    "    data['lemma'] = data['query'].apply(lambda x:' '.join([token.lemma_ for token in nlp(x) if token.lemma_ not in stop_words]))\n",
    "    data['keyword'] = data['lemma'].apply(lambda x: list(set([token.lemma_ for token in nlp(x) if token.lemma_ in keyword_list_lemma])))\n",
    "\n",
    "    data['noun'] = data['query'].apply(lambda x: list(set([token.lemma_ for token in nlp(x) if token.pos_ in ['NOUN','PROPN'] and token.lemma_ not in stop_words])))\n",
    "    data['verb'] = data['query'].apply(lambda x: list(set([token.lemma_ for token in nlp(x) if token.pos_ in ['VERB'] and token.lemma_ not in stop_words])))\n",
    "\n",
    "    data['noun'] = data['noun'].apply(lambda x: ' '.join([w for w in x]))\n",
    "    data['verb'] = data['verb'].apply(lambda x: ' '.join([w for w in x]))\n",
    "    data['keyword'] = data['keyword'].apply(lambda x: ' '.join([w for w in x]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>like copy -pron- statement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>send -pron- copy -pron- statement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              intent                              query  target  clusters_1  \\\n",
       "0  Statement request         like copy -pron- statement       0           0   \n",
       "1  Statement request  send -pron- copy -pron- statement       0           0   \n",
       "\n",
       "   clusters_2  clusters_3  \n",
       "0           2           3  \n",
       "1           2           3  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "      <th>lemma</th>\n",
       "      <th>keyword</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>like copy -pron- statement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>like copy -pron- statement</td>\n",
       "      <td>statement</td>\n",
       "      <td>copy statement -pron-</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statement request</td>\n",
       "      <td>send -pron- copy -pron- statement</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>send -pron- copy -pron- statement</td>\n",
       "      <td>statement</td>\n",
       "      <td>statement -pron-</td>\n",
       "      <td>copy send</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              intent                              query  target  clusters_1  \\\n",
       "0  Statement request         like copy -pron- statement       0           0   \n",
       "1  Statement request  send -pron- copy -pron- statement       0           0   \n",
       "\n",
       "   clusters_2  clusters_3                              lemma    keyword  \\\n",
       "0           2           3         like copy -pron- statement  statement   \n",
       "1           2           3  send -pron- copy -pron- statement  statement   \n",
       "\n",
       "                    noun       verb adj  \n",
       "0  copy statement -pron-                 \n",
       "1       statement -pron-  copy send      "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_nlp_features(df_train)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "      <th>lemma</th>\n",
       "      <th>keyword</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cancel credit card transaction</td>\n",
       "      <td>submit dispute</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>21</td>\n",
       "      <td>submit dispute</td>\n",
       "      <td>dispute</td>\n",
       "      <td>dispute</td>\n",
       "      <td>submit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost or compromised cards</td>\n",
       "      <td>lose -pron- card</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>lose -pron- card</td>\n",
       "      <td>card lose</td>\n",
       "      <td>card -pron-</td>\n",
       "      <td>lose</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           intent             query  target  clusters_1  \\\n",
       "0  Cancel credit card transaction    submit dispute      17          25   \n",
       "1       Lost or compromised cards  lose -pron- card      43          43   \n",
       "\n",
       "   clusters_2  clusters_3             lemma    keyword         noun    verb  \\\n",
       "0          69          21    submit dispute    dispute      dispute  submit   \n",
       "1          53          44  lose -pron- card  card lose  card -pron-    lose   \n",
       "\n",
       "  adj  \n",
       "0      \n",
       "1      "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = get_nlp_features(df_test_cluster_top_n)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine model score\n",
    "countvector_cols = ['lemma', 'keyword', 'noun', 'verb']\n",
    "top_clusters_cols = ['clusters_1', 'clusters_2', 'clusters_3']\n",
    "\n",
    "feature_cols = countvector_cols + top_clusters_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df_train, df_test, feature_cols):\n",
    "    \"\"\" split dataset, get X_train, X_test, y_train, y_test \"\"\"\n",
    "    X_train = df_train[feature_cols]\n",
    "    # print(X_train.head(1))\n",
    "    y_train = df_train['target']\n",
    "    # print(y_train.head(1))\n",
    "    X_test = df_test[feature_cols]\n",
    "    y_test = df_test['target']\n",
    "    # print(X_test.head(1))\n",
    "    # print(y_test.head(1))\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_train_test(df_train, df_test, feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nlp_to_x(X_train, X_test):\n",
    "    \"\"\" Add NLP features to input X \"\"\"\n",
    "    v_lemma = TfidfVectorizer()\n",
    "    x_train_lemma = v_lemma.fit_transform(X_train['lemma'])\n",
    "    x_test_lemma = v_lemma.transform(X_test['lemma'])\n",
    "    vocab_lemma = dict(v_lemma.vocabulary_)\n",
    "\n",
    "    v_keyword = TfidfVectorizer()\n",
    "    x_train_keyword = v_keyword.fit_transform(X_train['keyword'])\n",
    "    x_test_keyword = v_keyword.transform(X_test['keyword'])\n",
    "    vocab_keyword = dict(v_keyword.vocabulary_)\n",
    "\n",
    "    v_noun = TfidfVectorizer()\n",
    "    x_train_noun = v_noun.fit_transform(X_train['noun'])\n",
    "    x_test_noun = v_noun.transform(X_test['noun'])\n",
    "    vocab_noun = dict(v_noun.vocabulary_)\n",
    "\n",
    "    v_verb = TfidfVectorizer()\n",
    "    x_train_verb = v_verb.fit_transform(X_train['verb'])\n",
    "    x_test_verb = v_verb.transform(X_test['verb'])\n",
    "    vocab_verb = dict(v_verb.vocabulary_)\n",
    "    \n",
    "    # combine all features \n",
    "    x_train_combined = hstack((x_train_lemma,x_train_keyword,x_train_noun,x_train_verb,X_train[top_clusters_cols].values),format='csr')\n",
    "    x_train_combined_columns= v_lemma.get_feature_names()+v_keyword.get_feature_names()+v_noun.get_feature_names()+v_verb.get_feature_names()+top_clusters_cols\n",
    "\n",
    "    x_test_combined = hstack((x_test_lemma,x_test_keyword,x_test_noun,x_test_verb,X_test[top_clusters_cols].values),format='csr')\n",
    "    x_test_combined_columns= v_lemma.get_feature_names()+v_keyword.get_feature_names()+v_noun.get_feature_names()+v_verb.get_feature_names()+top_clusters_cols\n",
    "\n",
    "    x_train_combined = pd.DataFrame(x_train_combined.toarray())\n",
    "    x_train_combined.columns = x_train_combined_columns\n",
    "\n",
    "    x_test_combined = pd.DataFrame(x_test_combined.toarray())\n",
    "    x_test_combined.columns = x_test_combined_columns\n",
    "    \n",
    "    return x_train_combined, x_test_combined, v_lemma, v_keyword, v_noun, v_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_combined, x_test_combined, v_lemma, v_keyword, v_noun, v_verb = add_nlp_to_x(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=50, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build classifier\n",
    "clf = RandomForestClassifier(max_depth=50, n_estimators=1000)\n",
    "clf.fit(x_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_test_combined)\n",
    "best_3 = pd.DataFrame(np.argsort(probs, axis=1)[:,-3:],columns=['top3','top2','top1'])\n",
    "best_3['top1'] = clf.classes_[best_3['top1']]\n",
    "best_3['top2'] = clf.classes_[best_3['top2']]\n",
    "best_3['top3'] = clf.classes_[best_3['top3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([best_3.reset_index(drop=True),pd.DataFrame(y_test).reset_index(drop=True), X_test[feature_cols].reset_index(drop=True)], axis=1)\n",
    "score_1 = result[result['top1'] == result['target']].shape[0] / result.shape[0]\n",
    "score_2 = result[(result['top1'] == result['target']) | (result['top2'] == result['target'])].shape[0] / result.shape[0]\n",
    "score_3 = result[(result['top1'] == result['target']) | (result['top2'] == result['target'])| (result['top3'] == result['target'])].shape[0] / result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for top 1 clustering + classifier result is 75.8%\n",
      "Accuracy for top 2 clustering + classifier result is 82.8%\n",
      "Accuracy for top 3 clustering + classifier result is 85.9%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for top 1 clustering + classifier result is {:.1%}'.format(score_1))\n",
    "print('Accuracy for top 2 clustering + classifier result is {:.1%}'.format(score_2))\n",
    "print('Accuracy for top 3 clustering + classifier result is {:.1%}'.format(score_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare: Google NLU accuracy is 78.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "load model and run on one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "model_filename = 'RFClassifier.pkl'\n",
    "pickle.dump(clf, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vectorizer\n",
    "pickle.dump(v_lemma, open('TFIDFVectorizer_lemma', 'wb'))\n",
    "pickle.dump(v_keyword, open('TFIDFVectorizer_keyword', 'wb'))\n",
    "pickle.dump(v_noun, open('TFIDFVectorizer_noun', 'wb'))\n",
    "pickle.dump(v_verb, open('TFIDFVectorizer_verb', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"Please show me the current promotions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['query'])\n",
    "df.loc[0] = [test_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please show me the current promotions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   query\n",
       "0  Please show me the current promotions"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing test as well\n",
    "df['query'] = df['query'].apply(clean_text)\n",
    "df['query'] = df['query'].apply(nltk_tokenize)\n",
    "df['query'] = df['query'].apply(lambda x:' '.join([token.lemma_ for token in nlp(x) if token.lemma_ not in stop_words]))\n",
    "df['query'] = df['query'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_nlp_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>lemma</th>\n",
       "      <th>keyword</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-pron- current promotion</td>\n",
       "      <td>-pron- current promotion</td>\n",
       "      <td>promotion</td>\n",
       "      <td>promotion</td>\n",
       "      <td></td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      query                     lemma    keyword       noun  \\\n",
       "0  -pron- current promotion  -pron- current promotion  promotion  promotion   \n",
       "\n",
       "  verb      adj  \n",
       "0       current  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = get_distance_matrix_idf(df, intent_list, dict_cluster, word2vec, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>lemma</th>\n",
       "      <th>keyword</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>Statement request</th>\n",
       "      <th>Passbook savings accounts</th>\n",
       "      <th>Card statements</th>\n",
       "      <th>Credit card statement</th>\n",
       "      <th>...</th>\n",
       "      <th>Paying a cancelled credit card</th>\n",
       "      <th>How to close my account</th>\n",
       "      <th>Card dispute</th>\n",
       "      <th>Change credit card limit</th>\n",
       "      <th>Increase credit card limit</th>\n",
       "      <th>Decrease credit card limit</th>\n",
       "      <th>Credit card application rejection</th>\n",
       "      <th>Rebates</th>\n",
       "      <th>How to redeem rewards</th>\n",
       "      <th>Update details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-pron- current promotion</td>\n",
       "      <td>-pron- current promotion</td>\n",
       "      <td>promotion</td>\n",
       "      <td>promotion</td>\n",
       "      <td></td>\n",
       "      <td>current</td>\n",
       "      <td>0.896305</td>\n",
       "      <td>0.882283</td>\n",
       "      <td>0.818481</td>\n",
       "      <td>0.787504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815096</td>\n",
       "      <td>0.925912</td>\n",
       "      <td>0.75781</td>\n",
       "      <td>0.833953</td>\n",
       "      <td>0.814946</td>\n",
       "      <td>0.893213</td>\n",
       "      <td>0.761064</td>\n",
       "      <td>0.720189</td>\n",
       "      <td>0.785271</td>\n",
       "      <td>0.913706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      query                     lemma    keyword       noun  \\\n",
       "0  -pron- current promotion  -pron- current promotion  promotion  promotion   \n",
       "\n",
       "  verb      adj  Statement request  Passbook savings accounts  \\\n",
       "0       current           0.896305                   0.882283   \n",
       "\n",
       "   Card statements  Credit card statement  ...  \\\n",
       "0         0.818481               0.787504  ...   \n",
       "\n",
       "   Paying a cancelled credit card  How to close my account  Card dispute  \\\n",
       "0                        0.815096                 0.925912       0.75781   \n",
       "\n",
       "   Change credit card limit  Increase credit card limit  \\\n",
       "0                  0.833953                    0.814946   \n",
       "\n",
       "   Decrease credit card limit  Credit card application rejection   Rebates  \\\n",
       "0                    0.893213                           0.761064  0.720189   \n",
       "\n",
       "   How to redeem rewards  Update details  \n",
       "0               0.785271        0.913706  \n",
       "\n",
       "[1 rows x 83 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_3(data, intent_list):\n",
    "    data = data.copy()\n",
    "    cluster_cols = intent_list.copy()\n",
    "\n",
    "    data['clusters_top3'] = data.apply(lambda x: np.argsort(x[cluster_cols].values)[:3].tolist(), axis=1)\n",
    "\n",
    "    top_clusters_cols = pd.DataFrame(data['clusters_top3'].values.tolist(),columns = ['clusters_1','clusters_2','clusters_3']).reset_index(drop=True)\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = pd.concat([data,top_clusters_cols], axis=1)\n",
    "\n",
    "    data.drop(columns = 'clusters_top3', inplace=True)\n",
    "    data.drop(columns = cluster_cols, inplace=True)\n",
    "    \n",
    "    # print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = get_top_3(df_cluster, cluster_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>lemma</th>\n",
       "      <th>keyword</th>\n",
       "      <th>noun</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>clusters_1</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-pron- current promotion</td>\n",
       "      <td>-pron- current promotion</td>\n",
       "      <td>promotion</td>\n",
       "      <td>promotion</td>\n",
       "      <td></td>\n",
       "      <td>current</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      query                     lemma    keyword       noun  \\\n",
       "0  -pron- current promotion  -pron- current promotion  promotion  promotion   \n",
       "\n",
       "  verb      adj  clusters_1  clusters_2  clusters_3  \n",
       "0       current          45          46          56  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nlp(df, v_lemma, v_keyword, v_noun, v_verb, top_clusters_cols):\n",
    "    \"\"\" Add NLP features to input X \"\"\"\n",
    "    x_test_lemma = v_lemma.transform(df['lemma'])\n",
    "    x_test_keyword = v_keyword.transform(df['keyword'])\n",
    "    x_test_noun = v_noun.transform(df['noun'])\n",
    "    x_test_verb = v_verb.transform(df['verb'])\n",
    "    \n",
    "    # combine all features \n",
    "    x_test_combined = hstack((x_test_lemma,\n",
    "                              x_test_keyword,\n",
    "                              x_test_noun,\n",
    "                              x_test_verb,\n",
    "                              df[top_clusters_cols].values),format='csr')\n",
    "\n",
    "    x_test_combined_columns = v_lemma.get_feature_names()+\\\n",
    "                              v_keyword.get_feature_names()+\\\n",
    "                              v_noun.get_feature_names()+\\\n",
    "                              v_verb.get_feature_names()+\\\n",
    "                              top_clusters_cols\n",
    "    \n",
    "    x_test_combined = pd.DataFrame(x_test_combined.toarray())\n",
    "    x_test_combined.columns = x_test_combined_columns\n",
    "    \n",
    "    return x_test_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = add_nlp(top_3, v_lemma, v_keyword, v_noun, v_verb, top_clusters_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(X_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_3 = pd.DataFrame(np.argsort(probs, axis=1)[:,-3:],columns=['top3','top2','top1'])\n",
    "best_3['top1'] = clf.classes_[best_3['top1']]\n",
    "best_3['top2'] = clf.classes_[best_3['top2']]\n",
    "best_3['top3'] = clf.classes_[best_3['top3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top3</th>\n",
       "      <th>top2</th>\n",
       "      <th>top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top3  top2  top1\n",
       "0    62    46    45"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2intent = {y:x for x,y in intent2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_name(index, index2intent=index2intent):\n",
    "    return index2intent[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_3['top1_name'] = best_3['top1'].apply(get_target_name)\n",
    "best_3['top2_name'] = best_3['top2'].apply(get_target_name)\n",
    "best_3['top3_name'] = best_3['top3'].apply(get_target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top3</th>\n",
       "      <th>top2</th>\n",
       "      <th>top1</th>\n",
       "      <th>top1_name</th>\n",
       "      <th>top2_name</th>\n",
       "      <th>top3_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>Promotions</td>\n",
       "      <td>Card Promotions</td>\n",
       "      <td>Uplift suspension on accounts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top3  top2  top1   top1_name        top2_name  \\\n",
       "0    62    46    45  Promotions  Card Promotions   \n",
       "\n",
       "                       top3_name  \n",
       "0  Uplift suspension on accounts  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = best_3.at[0,'top1_name']\n",
    "top2 = best_3.at[0,'top2_name']\n",
    "top3 = best_3.at[0,'top3_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sentence:\n",
      "Please show me the current promotions\n",
      "\n",
      "Top 1 prediction intent is Promotions\n",
      "Top 2 prediction intent is Card Promotions\n",
      "Top 3 prediction intent is Uplift suspension on accounts\n"
     ]
    }
   ],
   "source": [
    "print(f'For sentence:\\n{test_query}\\n')\n",
    "print(f'Top 1 prediction intent is {top1}')\n",
    "print(f'Top 2 prediction intent is {top2}')\n",
    "print(f'Top 3 prediction intent is {top3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_nlp(query, classifier_intent_nlp):\n",
    "    \"\"\" load classification model outside the function  \n",
    "        \n",
    "        return a dataframe df\n",
    "        columns: pred_seq, intent_class, intent_string, pred_prob\n",
    "        rows: top 3 prediciton, example for first row: 1, 0, Promotions, 0.66\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intent_nlp_clustering(query, classifier_intent_nlp_clustering, word2vec):\n",
    "    \"\"\" load word2vec dict outside the function\n",
    "        load classification model outside the function \n",
    "\n",
    "        return a dataframe df\n",
    "        columns: pred_seq, intent_class, intent_string, pred_prob\n",
    "        rows: top 3 prediciton, example for first row: 1, 0, Promotions, 0.66\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:alert]",
   "language": "python",
   "name": "conda-env-alert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
